{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main purpose of this tutorial is to ease the implementation of our library `scikit-activeml` to new users. `scikit-activeml` is a library that executes the most important query strategies. It is built upon the well-known machine learning frame-work `scikit-learn`, which makes it user-friendly. For better understanding, we show an exemplary active learning cycle here. Let's start by importing the relevant packages from both `scikit-learn` and `scikit-activeml`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from skactiveml.pool import UncertaintySampling\n",
    "from skactiveml.utils import is_unlabeled, MISSING_LABEL, plot_2d_dataset\n",
    "from skactiveml.classifier import SklearnClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set Generation\n",
    "We generate a data set of 100 data points with two clusters from the `make_classification` method of `scikit-learn`. This method also returns the true labels of each data point. In practice, however, we do not know these labels unless we ask an oracle. The labels are stored in `y_true`, which acts as an oracle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_true = make_classification(n_features=2, n_redundant=0, random_state=0)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_true)\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Data set');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "Our goal is to classify the data points into two classes. To do so, we introduce a vector `y` to store the labels that we acquire from the oracle (`y_true`). As shown below, the vector `y` is unlabeled at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.full(shape=y_true.shape, fill_value=MISSING_LABEL)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many easy-to-use classification algorithms in `scikit-learn`. In this example, we use the logistic regression classifier. Details of other classifiers can be accessed from here: https://scikit-activeml.readthedocs.io/en/latest/api/classifier.html. As `scikit-learn` classifiers cannot cope with missing labels, we need to wrap these with the `SklearnClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SklearnClassifier(LogisticRegression(),  classes=np.unique(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Strategy\n",
    "The query strategies are the central part of our library. In this example, we use uncertainty sampling with entropy to determine the most uncertain data points. All implemented strategies can be accessed from here: https://scikit-activeml.readthedocs.io/en/latest/api/pool.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = UncertaintySampling(clf, method='entropy', random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learning Cycle\n",
    "As an example, we choose to loop around the active learning cycle *20* times (`n_cycles`), and the number of labels to be acquired is the multiplication of `batch_size` and `n_cycles`. \n",
    "Inside the loop, we first get the unlabeled indices of vector `y`. All the indices for *100* data points are unlabeled, because we are at the first iteration. Then, we use those unlabeled indices to create a list of labeling set, which contain unlabeled data set, and ask the query strategy to give us the indices of the most informative data points in `X_cand`. It will return indices that are equal to the number of`batch_size`, and data point corresponds to these indices are the most informative ones to be labeled. In our case, the output is just a single index, because the `batch_size` is *1*.\n",
    "Finally, we ask the oracle for the true label of the selected data point and store it in vector `y` to train our classifier. We continue until we reach the *20* labeled data points. \n",
    "Below, we see the implementation of an active learning cycle. The first figure shows the decision boundary after acquiring the label of two data points. The second figure is after having *10* labeled data points from the oracle, which shows significant improvement compare to the first figure. The last figure shows the decision boundary after acquiring labels for *20* data points. Finally, we use the accurcy score as a performance measure, which shows the accuracy of our classifer at specified iterations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learning Cycle\n",
    "In this example, we perform 20 iterations of the active learning cycle (`n_cycles=20`). In each iteration, we acquire one label (`batch_size=1`). The total number of labels to be acquired is `batch_size * n_cycles`. \n",
    "Inside the loop, we first get the indices of the unlabeled instances. In the first iteration, `unlbld_idx` contains all indices because all data points are unlabeled. Next, we use the unlabeled indices to create the list `X_cand` of candidate instances that can still be queried and ask the query strategy to give us the indices of the most informative data points in `X_cand`. The `query` method returns the indices of the best `batch_size` instances together with the corresponding instances. In our case, the output is just a single index, as `batch_size=1`.\n",
    "\n",
    "Finally, we ask the oracle for the true label of the selected data point and store it in `y` to train our classifier. We continue until we reach the 20 labeled data points. \n",
    "Below, we see the implementation of an active learning cycle. The first figure shows the decision boundary after acquiring the label of two data points. The second figure shows the decision boundary with 10 acquired labels, which shows significant improvement compared to the first figure. The last figure shows the decision boundary after acquiring labels for 20 data points. Finally, we use the accuracy score as a performance measure, which shows the accuracy of our classifier in the specified iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_cycles = 20\n",
    "y = np.full(shape=y_true.shape, fill_value=MISSING_LABEL)\n",
    "for c in range(n_cycles):\n",
    "    unlbld_idx = np.where(is_unlabeled(y))[0]\n",
    "    X_cand = X[unlbld_idx]\n",
    "    query_idx = unlbld_idx[qs.query(X_cand=X_cand, X=X, y=y, batch_size=1)]\n",
    "    y[query_idx] = y_true[query_idx]\n",
    "    clf.fit(X, y)\n",
    "    if c in [1, 9, 19]:\n",
    "        y_pred = clf.predict(X)\n",
    "        plot_2d_dataset(X, y, y_true, clf, qs)\n",
    "        print('The accuracy score is {} for {} iterations.'.format(accuracy_score(y_true, y_pred), np.sum(~np.isnan(y))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
